% !TeX spellcheck = en_US

\chapter{Basics}
\label{chap:basis}
In this chapter, the fundamentals used in this work will be explained.
These include definitions for Cloud Computing and Cloud Applications, description of the TOSCA standard and the OpenTOSCA runtime environment.
At the end, the overview of package management, file download and tools for its automation will be presented.
\section{Cloud Computing and Cloud Application} \label{sec:cloud}
To understand problems of \emph{Cloud Computing} we require a clear definition of this term.
%In everyday life, you can often hear the phrase "Cloud Computing", but what is it?\\
%\subsection{Definitions}
Unfortunately, a generally accepted definition of Cloud Computing that describes all possible situations doesn't exist. 
But in the scientific community, the definition put forward by \gls{nist}~\cite*{wwwnist} is commonly used. 
This definition appropriately describes the concept of Cloud Computing used in this paper, and therefore this definition will be used:\\
%\begin{definition}[Cloud Computing]
\emph{\textbf{Cloud Computing}\label{def:nist} is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction~\cite*{nist}.}\\
%\end{definition}
%But computing is too abstract term, for our purpose we need something more practical, like an application.
Also the is no generally accepted definition of Cloud Application, but it will be defined for this work using the Cloud Computing term.
%\begin{definition}[Cloud Application] 
A \textbf{Cloud Application}\label{def:capp} is an application that is executed according to the Cloud Computing model. %\\%~\cite*{cloudapp}\\
%\end{definition} 
In addition, a short meanings of a Cloud system, a provider, and a consumer will be defined too.
%\begin{definition}[Cloud system] 
A composite Cloud Application which consists of multiple small applications will be called a \textbf{Cloud system}\label{def:csys}. %\\
%\end{definition} 
%\subsubsection{Sides}
An owner of a physical platform, where Cloud Computing takes place will be called a \textbf{provider}, an owner of a Cloud Application renting a provider's platform will be called a \textbf{consumer}~\cite{viewCC}.
%\clearpage
%\subsection*{Service Models} 
\\
\label{def:servmod}
Providers grant access to a wide range of different services: software, hardware devices, etc.
Some groups of services which follow the common rules and perform the similar function are described by service models.
NIST distinguishes between three main types of such models:
\begin{itemize}
	\item  \gls{saas}. 
	The capability provided to the consumer is to use the provider’s applications running on a Cloud infrastructure. 
	The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. 
	The consumer does not manage or control the underlying Cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited userspecific application configuration settings~\cite*{nist}.
	\item \gls{paas}. 
	The capability provided to the consumer is to deploy onto the Cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider.
	The consumer does not manage or control the underlying Cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment~\cite*{nist}.
	\item \gls{iaas}.
	The capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the
	consumer is able to deploy and run arbitrary software, which can include operating systems and applications.
	The consumer does not manage or control the underlying Cloud infrastructure but has control over operating systems, storage, and deployed applications; and possibly limited control of select networking components (e.g., host firewalls)~\cite*{nist}.
\end{itemize}
%\subsection*{Deployment models}
%Similarly, NIST distinguishes between four types of deployment models.
%\begin{itemize}
%	\item Private cloud. 
%	The cloud infrastructure is provisioned for exclusive use by a single organization comprising multiple consumers (e.g., business units). It may be owned, managed, and operated by the organization, a third party, or some combination of them, and it may exist on or off premises.
%\item Community cloud.
%	The cloud infrastructure is provisioned for exclusive use by a specific community of consumers from organizations that have shared concerns (e.g., mission, security requirements, policy, and compliance considerations).
%	It may be owned, managed, and operated by one or more of the organizations in the community, a third party, or some combination of them, and it may exist on or off premises.
%\item Public cloud.
%	The cloud infrastructure is provisioned for open use by the general public. 
%	It may be owned, managed, and operated by a business, academic, or government organization, or some combination of them.
%	It exists on the premises of the cloud provider.
%\item Hybrid cloud. 
%	The cloud infrastructure is a composition of two or more distinct cloud infrastructures (private, community, or public) that remain unique entities, but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load balancing between clouds). 
%\end{itemize}
\subsection*{Usage of Cloud Computations}
Nowadays Cloud Computing and applications can be found everywhere, and their number constantly grows~\cite*{cloud_stat}.
They are used for test and development, big data analyses, file storage, etc.
Cloud Computing allows using resources effectively, to distribute the load to a multi-server system and to shift the maintenance to the providers. 
If  a service uses a single physical server and this server will be disabled, then the entire service will be completely unavailable too.
But if a Cloud Application uses a hundred of physical servers, then disabling of one will not carry such serious consequences.
In addition, a consumer doesn't need to maintain a team of administrators for the event of various problems.\\
A consumer doesn't have a direct access to the infrastructure (servers and operating systems) when using a PaaS or a SaaS service models. 
He can operate only with the provided Application Programming Interface (API).
An API defines a set of methods to communicate with provider's infrastructure. 
Each provider prepares his own set of methods depending on his area of specialization. 
On the one hand, this specialization makes easier to work with the provider, but on the other hand, it becomes more difficult to redeploy an application to another provider.
\section{Topology and Orchestration Specification for Cloud	Applications} \label{sec:tosca}
%\subsection*{Definition}
The \textbf{T}opology and \textbf{O}rchestration \textbf{S}pecification for \textbf{C}loud \textbf{A}pplications (\gls{tosca}) standard developed by \gls{oasis}~\cite{oasis} provides an opportunity to enable portable automated deployment and management of Cloud Applications.
\gls{tosca} describes the structure of an application as a topology containing components and relationships between them.
%Plans capture management tasks by orchestrating management operations exposed by the components. \cite*{INBOOK-2014-01}
\gls{tosca} application is a Cloud Application described according to the TOSCA standard which can be used to describe all stages of TOSCA Applications life-cycle.
To process TOSCA applications a TOSCA runtime environment must be executed on the provider's platform. 
The runtime environments can process applications and serve as a layer between the Cloud Application and provider's API.
That allows to implement a single application suitable for working with different providers. 
\subsection*{Structure of TOSCA Applications}
TOSCA specification provides a language to define components of TOSCA application and relationships between them. % using $Service$ $Templates$. 
In addition it describes the management procedures which create or modify services using orchestration processes.
The description of elements of a TOSCA structure used in this work is provided. \\
$Service$ $Templates$ are the main components of a \gls{tosca} structure. 
They define Cloud services provided by TOSCA application as a combination of the structure (Topology Template) and process models (Plans).
It must be at least one Service Template within one TOSCA application.
The combination of topology and orchestration defines what is needed to be preserved across operation in different environments.
Thus it guarantees the interoperable deployment and management of Cloud services throughout the complete life-cycle and is useful when they are ported to alternative providers~\cite{TOSCA-v1.0_book}. \\ %\\
$Plans$ provide capabilities to manage Cloud Applications, especially their creation and termination.
These components combine management capabilities to create high-level management tasks which can then be executed for fully automated deployment, configuration and other operations of the application.
Plans can be started by a user or fully automatically and call management operations of the nodes in the topology. %\\
A $Topology$ $Template$ describes the topology of a Cloud Application, defining nodes (Node Templates) and relations between them (Relationship Templates). %\\
A $Node$ $Template$ instantiates a Node Type as a component of a service. 
A $Node$ $Type$ defines the properties of such a component and the operations available to manipulate the component.
A $Relationship$ $Template$ instantiates a Relationship Type as a relationship between Node Templates in a Topology Template. 
The Relationship Template indicates that two nodes are connected and defines the direction of the connection.
A $Relationship$ $Type$ defines semantics and properties of the relationship.\label{subs:reltype} %\\
A Node Type and Relationship Type can be instantiated multiple times.
Those types are like abstract classes in high-level programming languages and Templates are objects of those classes.\\
A simple cloud Application for weather calculation can be considered to provide an example. 
The calculation is performed by a python script which requires a python environment that is hosted on an Ubuntu virtual server.
$Node$ $Types$ must be defined for the python script, python environment and Ubuntu server.  
These $Node$ $Types$ will describe available operations for defined components.
It will be the $compute$ operation for the python script, the $install$ operation for the python environments and the $deploy$ and $shutdown$ operations for the server.
Additionally, one must define $Relationship$ $Types$ for $requires$ and $hosted$ $on$ dependencies.
Then these types will be instantiated inside the $Topology$ $Template$ named $weater$ $calculator$.
For each specified $Node$ $Type$, a corresponding $Node$ $Template$ with unique identifiers is created.
These identifiers are used by $Relationship$ $Templates$ to define the dependencies.
Figure~\ref{fig:weather} presents the described application. \\
Artifact represents the content necessary such as executables (e.g. a script or an executable program), configuration files, data files, or something that might be needed for other executables (e.g. libraries or images of file system).
TOSCA distinguishes two kinds of artifacts: $Implementation$ $Artifacts$ and $Deployment$ $Artifacts$.
$Implementation$ $Artifacts$ represent the implementation of an operation described by a Node Type.
$Deployment$ $Artifacts$ represent the content needed to materialize an instances of a Node Type.
In the example with the weather calculation, the python script will be an $Implementation$ $Artifact$ associated with the $compute$ operation and the image of the Ubuntu virtual server will be a $Deployment$ $Artifact$.
$Artifact$ $Types$ describe types of artifact: python script, installation package, etc.
$Artifact$ $Templates$ are used to describe artifacts itself.
Each $Artifact$ $Template$ contains information about one artifact: the location of the artifact, artifact type and other attended data. 
%As in the example with nodes above, types are like classes, templates are like objects, and artifacts represent content or a value of an object, but these values can't be changed. %\\
$Node$ $Type$ $Implementations$ combine information about artifacts implementing the corresponding Node Type.
If a Node Type contains $deploy$ and $shutdown$ operations, then the corresponding Node Type Implementation can contain two Implementation Artifacts with scripts implementing these operations and one Deployment Artifact with data necessary for the materializing instances of nodes. %\\
Implementations are like final classes between Node Types and Node Templates, but in TOSCA standard, the Implementation will be chosen only during execution.
Types, Templates, and Implementations defining a TOSCA application are stored in definition document which have the XML format. %\\
%%\subsection*{Usage}
%The combination of topology and orchestration in a Service Template defines what is needed to be preserved across deployments in different environments to enable interoperable deployment of Cloud services and their management throughout the complete lifecycle (e.g. scaling, patching, monitoring, etc.).
%This is useful when an application is ported to alternative Cloud environments.~\cite{TOSCA-v1.0_book} \\
\input{graphics/weather}
%
\subsection*{CSAR} 
%
To pack a TOSCA application a \gls{csar}\label{sec:csar} is used.
This is a ZIP-file with ".csar" extension that contains all the data needed for instantiation and management of TOSCA application.
They include definition documents, artifacts, etc.
In this form, a TOSCA application can be processed by a TOSCA runtime environment.\\
%\subsubsection*{Structure}
The root folder of any CSAR must contain the "Definitions" and "\gls{tosca}-Metadata" folders.
The "Definitions" folder contains definition documents one of which must define a Service Template.
The "\gls{tosca}-Metadata" folder must contain TOSCA metadata in the form of a file with the "TOSCA.meta" name.
This metafile consists of name/value pairs, one line for each pair. 
The first set of pairs describes CSAR itself (TOSCA version, CSAR version, creator, etc). 
All other pairs represent metadata of files from the CSAR. 
The metadata is used by a TOSCA runtime environment to process given files correctly.\\
%
%\subsubsection*{Terms}
%During this work, such terms as input CSAR and output CSAR will be used.
%The input \gls{csar} is the \gls{csar}, which can contain external references and will be processed by the framework. %\\
%The output CSAR is the CSAR, which was processed by the framework and doesn't contain external references. %(at least those that are handled by the framework).

\section{OpenTOSCA} \label{sec:opentosca}
OpenTOSCA provides an open source ecosystem for \gls{tosca} based applications. 
%It was developed at the University of Stuttgart in october 2012.
This ecosystem consists of three parts: the \gls{tosca} \textbf{runtime environment}, the graphical TOSCA modeling tool \textbf{Winery}, and the self-service portal for the applications available in the container \textbf{Vinothek}~\cite*{OpenTOSCA}.
Descriptions of the runtime environment and Winery will be provided in more detail in the following. 
\subsection*{Runtime Environment}
In this section, the OpenTOSCA runtime environment will be presented.
The runtime environment enables a fully automated plan-based deployment and management of TOSCA Applications presented by CSARs. 
It contains five main components: Controller, Implementation Artifact Engine, Plan Engine, Database and Container API.
Container API provides in interface to communicate with Controller which  start plans, controls other components, tracks their progress, and interprets the TOSCA application.
Implementation Artifact Engine is responsible to make implementation artifacts accessible for Plan Engine and execute them fully automatically.
It has the plugin architecture which ensures extensibility.
Implementation Artifacts are processed by the corresponding plugin which knows where and how to run this kind of artifact. 
The plugins deploy the respective artifacts for execution and save into Database endpoints which can be called by Plan Engine to start the artifacts.
The deployment of Web Archives on Tomcat~\cite*{tomcat}, Axis Archives on Apache Axis~\cite*{axis} and many others is supported~\cite*{macharb}.
The Plan Engine handles plans in the same manner.
It is built according to a plugin architecture too and supports different workflow languages, e.g., \gls{bpmi} or \gls{bpel}, and their runtime environments~\cite{INPROC-2013-45}.
Plan Engine plugins deploy supported plans and save endpoints into Database.
Database stores all files Presented in a CSAR and endpoints of deployed artifacts and plans.
%The architecture of the environment is visualized by Figure~\ref{fig:openarch}.
\\
A processing is done in following manner.  
First, the CSAR is unpacked and the files are put into Database.
Then, the TOSCA definitions documents are loaded, resolved, validated, and processed by the Control component, which calls the Implementation Artifact Engine and the Plan Engine.
The Implementation Artifact Engine deploys the referenced Implementation Artifacts and stores their endpoints in the Endpoints database. 
Finally, the Plan Engine binds and deploys the application’s management plans.
The endpoints of the management plans are stored in the Plans database too~\cite{INPROC-2013-45}.
%\input{graphics/opencontainer}
%\input{graphics/openarch}
\subsection*{Winery}\label{subs:wine}\label{tool:winery}
Winery provides a complete set of functions for graphically create, edit and delete elements in the TOSCA topology. 
It operates with CSARs and consists of four parts: the type and template management, the topology modeler, the BPMN4TOSCA plan modeler ~\cite{BPMN4TOSCA}, and the repository.\\
The type, template and artifact management enables management of all TOSCA types, templates and related artifacts. 
This includes node types, relationship types, policy types, artifact types, artifact templates, and artifacts such as virtual machine images.\\
The topology modeler allows to create service templates which consist of node templates and relationship templates. 
They can be annotated with requirements and capabilities, properties, and policies.\\
BPMN4TOSCA plan modeler offers web-based creation of BPMN models with the TOSCA extension, BPMN4TOSCA. 
That means the modeler supports the BPMN elements and structures required by TOSCA plans and not the full set of BPMN. 
The Stardust project~\cite*{stardust} offers Browser Modeler, which covers all phases of the Business Process Lifecycle including modeling, simulation, execution and monitoring. 
In the context of Winery, this modeler was extended to support BPMN4TOSCA.\\
The repository stores TOSCA models and allows managing their content. 
For instance, node types, policy types, and artifact templates are managed by the repository. 
The repository is also responsible for importing and exporting CSARs, the exchange format of TOSCA files and related artifacts~\cite{winery}. %\\
%Winery works under a Tomcat server and therefore a visual interface is available in a browser. %, example in Figure \ref{fig:winery_gui}.
An example of the TOSCA topology visualization is presented in Figure~\ref{fig:winery_source}.
%\begin{figure}[ht]   
%	\centering
%	\includegraphics[width=0.7\textwidth]{Screenshot_winery_gui.png}
%	\caption{Visual interface for $Winery$.}
%	\label{fig:winery_gui}
%\end{figure}
\begin{figure}[ht]   
\centering
\includegraphics[width=0.7\textwidth]{Screenshot_winery_source2.png}
\caption{The TOSCA Application visualized by $Winery$.}
\label{fig:winery_source}
\end{figure}
\section{Package Management} \label{sec:pm}
The package management in Unix-like operating systems is described in this section.
It handles the installation, update, configuration and remove of packages or in other word the management of packages.
%An installation of packages from external sources represents an external reference and therefore they will be considered in order to identify such references.
%\subsection*{Package managers}
Packages are archive files containing both data for installation of the program components and a sets of metadata like name, function, version, producer, and a list of dependencies to other packages~\cite*{opium}. 
One package can present not only a complete program but also a certain component of a large application.
Usually packages are stored in external web repositories which can be accessed by a user or a package management tool to download the necessary packages. % or libraries, a packages which can be used only by other programs.
In this work, we are trying to eliminate usage of such external sources.\\
For a user, a package manager is a set of software tools which automate the management of packages.
But from the operating system side, a package manager is used to handle the database of packages, their dependencies, and versions, to prevent erroneous installation of programs and missing dependencies.
%\subsection*{Packages}
%\subsection*{Dynamic libraries}
This task is especially complex in computer systems relying on dynamic library linking. 
These systems share executable libraries of machine instructions across  applications. 
Complex relationships between different packages requiring different versions of libraries result in a challenge colloquially known as "dependency hell"~\cite*{linuxgeek}.
Good package management is vital to these systems.\\
%\subsection*{Repository}
To give users more control over the kinds of programs that they allow to install on their systems, packages are often downloaded only from a number of software repositories.
In Unix-like systems, a package manager uses official repositories appropriate for the operating system and the architecture  of device where it's operate, but it's possible to use additional repositories, like third-party repositories or repositories for another architecture.\\
%\subsection*{Dependencies} \label{subs:dep}
Package managers distinguish between two types of dependencies: $required$ and $preRequired$. %\\
Dependency $package1$ \textbf{$required$} $package2$ indicates that the $package2$ must be installed for a proper \textbf{operation} of the $package1$. %\\
Dependency $package1$ \textbf{$preRequired$} $package2$ indicates that the $package2$ must be installed for a proper \textbf{installation} of the $package1$. %\\
%An example for obtaining the dependency list for the Python package is shown in Listing~\ref{lst:dep}.
%\begin{lstlisting}[caption={Example of using $apt$-$cache$ to obtain dependency list for package python}\label{lst:dep},captionpos=t] 
%user@user:~$ apt-cache depends python
%python
%PreDepends: python-minimal
%Depends: python2.7
%Depends: libpython-stdlib
%Conflicts: <python-central>
%Breaks: update-manager-core
%Suggests: python-doc
%Suggests: python-tk
%Replaces: python-dev
%\end{lstlisting}
%\subsection*{Dependency tree}
In these examples, the $package2$ is needed for the $package1$, but the $package2$ itself can require additional packages.
A structure describing all necessary packages and dependencies between them for the given root-package is called a dependency tree. 
The dependency type $required$ can lead to cycles in dependency trees which differs them from the normal tree graph structures.
\subsection*{Example Dependencies Handling}\label{subs:depapt}
Its necessary to define the principle of operation of common package managers to determine methods of encapsulation of their work.
Therefore, the $apt$-$get$ package manager will be considered to provide an example of execution.
This application is part of \gls{apt} program which uses $dpkg$ application to communicate with an operating system.
The system keeps a database of packages and their condition.
These relations are presented in Figure~\ref{fig:packages}.\\
$apt$-$get$ has many functions: install, remove, update, autoremove, download, etc.
We will consider the install, remove and autoremove operations to present the common algorithms of processing.
When a package manager becomes a $package$ installation command, it builds a dependencies tree for the $package$ and checks the possibility to install these depended packages.
For example, it must check the compatibility with previously installed packages. 
If the check was successful, the $apt$-$get$ downloads and installs the packages starting with the bottom of the tree.
The $package$ is marked in the database as manually installed and all the other packages are marked as automatically installed. 
It will be helpful during the autoremove operation when all automatically installed packages will be checked whether they are still needed.
After installation of packages from the dependencies tree, the $package$ will be ready to work.\\
A $package$ can be deleted during the $remove$ $package$ command.
It happens only if there are no other packages depending on the $package$. 
If the deletion is very important, then these packages can also be removed too to keep the consistency of the database. 
The packages necessary for the $package$ itself will be deleted only by the autoremove command.
\input{graphics/packages}
\section{Configuration Management}\label{sec:confman}
In this section the $configuration management$ will be described. 
Configuration is the specific state of the operating system.
It describes what packages need to be installed, what accounts must be created, what files need to be downloaded, where they must be stored and other necessary characteristics.
One can define all these setting in an configuration file which can be proceed by corresponding configuration management tool to achieve specified state.
During proceeding, configuration management tools can use package managers and data download utilities which handle external references.
Data download utilities are used to get necessary data from remote sources.
That can be database images, other configuration files, etc.
Common configuration management tools like Ansible, Chef and CFEngine will be presented.
Additionally the Bash language and the Wget and cURL data download utilities will be described. 

\subsubsection*{Ansible} \label{lang:ansible}
$Ansible$ is an open-source automation engine. % that automates software provisioning, configuration management, and application deployment.
As with most configuration management software, Ansible has two types of servers: controlling machines and nodes.
First, there is a single controlling machine which is where orchestration begins.
Nodes are managed by a controlling machine over SSH.
The controlling machine describes the location of nodes through its inventory.
Ansible playbooks express configurations, deployment, and orchestration in Ansible.
The playbook format is YAML. 
Each playbook maps a group of hosts to a set of roles.
Each role is represented by calls to Ansible tasks~\cite{ansible}.
\subsubsection*{Chef} \label{lang:shef}
$Chef$ is a configuration management tool, which uses Ruby for writing system configuration files called "recipes".
They describe how Chef manages applications and utilities and how they are to be configured.
These recipes which can be grouped together as a "cookbook" for easier management define a series of resources that should be in a particular state: packages that should be installed, services that should be running, or files that should be written.
Chef can run in client/server mode, or in a standalone configuration named "chef-solo".
In client/server mode, the Chef client sends various attributes about the node to the Chef server. 
In solo mode the local system will be configured~\cite{chef}.
\subsubsection*{CFEngine}
$CFEngine$ is an open source configuration management system.
Its primary function is to provide automated configuration and maintenance of large-scale computer systems, including the unified management of servers, desktops, consumer and industrial devices, embedded networked devices, mobile smartphones, and tablet computers~\cite{cfengine}.
Configurations are described by "policy" files, which are plain text-files with .cf extension.
These files define the necessary state of files, packages, users, processes, services, etc~\cite{cfengine2}.
\subsubsection*{Bash} \label{lang:bash}
$Bash$ is a Unix command language written as a free software.
It isn't a configuration management tool, but provides enough capabilities to be used as if it is.
In addition Bash denotes a command processor that typically runs in a text window, where a user types commands that cause actions.
Bash is examined because it is very popular since it is the default command line processor in Unix-like systems~\cite*{bashdef}.
%Instead of typing commands direct into a command line, a script can be executed directly~\cite{bash}.
%A script is a file containing different commands which check an environment and call package managers and tools for data download to install the necessary packages and download the necessary data.
Executable file containing bash commands are called scripts.
We are interesting in these scripts which are used to configure a system: check environment, call package managers and data download utilities, etc.
%Bash is a very popular and ease language, therefore a huge number of problems have solutions in Bash scripts already.

\subsubsection*{Wget}
GNU $Wget$ is a utility designed for retrieving binary documents across the Web, through the use of HTTP and FTP.
Wget is non-interactive, which means it can work in the background, while the user is not logged in~\cite{wget_desc}.
This tool is suitable for automatically  tasks because it has built-in mechanism for the server response analyze.
A user can setup it to repeat download a certain number of times in case of fault.
Additionally Wget supports recursion mechanism which allows to download folders as simple as a single files.
\subsubsection*{cURL}
$cURL$ is a command line tool to transfer the data.
 It is based on libcurl a free open source library ported to a big number of platforms and supports a various protocols.
Due to this portability, cURL is often used in small embedded devices to transfer data~\cite{curl}.