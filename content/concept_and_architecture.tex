% !TeX spellcheck = en_US

\chapter{Concept and Architecture}\label{chap:conarch}
In this chapter, the concept and the architecture of the framework which can satisfy the requirements will be explained and substantiated.
Solutions to some additional problems will be presented. 
\section{Concept}
In this section, the main concept of this work are described.
The general structure of the framework is visualized in Figure~\ref{fig:gen}. 
In section~\ref{subs:analyse}, it will be explained how to determine the Node Templates which use the given artifact.
Then language modules and package manager modules functionality will be presented.
In section~\ref{subs:repres}, it will be expressed how to create a new node for a TOSCA topology. 
After that, a problem of the determination the architecture of the final platform will be explained and a solution presented.
In addition, it will be described, how the results can be validated.
\input{graphics/general}


\subsection{Analysis of a TOSCA-Topology}\label{subs:analyse}
To update the \gls{tosca} topology properly, it is necessary to add references from the nodes where external references were to the newly created nodes which resolve the external references. 
According to TOSCA standard, references between Node Templates can only be created in the same Service Template.  
That means that each Node Template which uses artifacts with external references must be found.
Furthermore, Service Template where these Node Templates are instantiated must be determined to create there a Node Template for the new nodes and reference them to the Node Templates with external references.
The pointers to artifacts are contained by Artifact Templates which are used by Node Type Implementations.
By composing all the information the simple references chain can be built:\\
$Artifact$ $\rightarrow$ $Artifact$~$Template$ $\rightarrow$ $Node$~$Type$~$Implementation$ $\rightarrow$ $Node$~$Type$ $\rightarrow$ $Node$~$Template$ $\rightarrow$ $Service$~$Template$\\
Now consider the references in more detail. 
\begin{itemize}
	\item $Artifact$ $\rightarrow$ $Artifact$ $Template$\\
	An Artifact can be referenced by several Artifact Templates. (Despite the fact that this is a bad practice.)
	\item  $Artifact$ $Template$ $\rightarrow$ $Node$ $Type$ $Implementation$ \\
	The same way an Artifact Template can be used by several Node Type Implementations.
	\item $Node$ $Type$ $Implementation$ $\rightarrow$ $Node$ $Type$ \\
	A Node Type Implementation can describe an implementation of only one Node Type.
	\item  $Node$ $Type$ $\rightarrow$ $Node$ $Template$\\
	Each Node Type can have any number of Node Templates.
	\item  $Node$ $Template$ $\rightarrow$ $Service$ $Template$\\
	But each Node Template is instantiated only once.
\end{itemize}
This structure can be described as a tree with an Artifact as a root, and Service Templates as leaves (The example is on Figure \ref{fig:script_serv}) and will be called the internal dependencies tree.\\
%Of course it is possible to move in opposite direction, starting from a Node and moving toward scripts, but this method brings additional complexity. 
There is an additional problem in the reference between a Node Type and a Node Type Implementation.
A Node Type can have several implementations, but which one will be used is determined only during the deployment. 
The chosen solution to this problem is to use each Node Type Implementation in the hope, that they will not conflict.\\
%The method presented above can uniquely determine Node Templates and Service Template for a given script.
%Of course it is not guaranteed that found Node Type Implementation will be used during deployment, but we can't do anything with this. 
The following steps to build the internal dependencies tree can be executed during the preprocessing.
\begin{itemize}
	\item Find all Artifact Templates to build references from Artifacts to Artifact Templates.
	\item Find all Node Type Implementations. Since they contain references both to the Node Type and to the Artifact Templates, so the dependency from Artifact to Node Types can be built.
	\item Find all Service Templates and all contained Node Templates they contain. Each Node Template contains a reference to Node Type what is useful for building a dependency from Artifact to Node Template.
\end{itemize} 
In this way the required internal dependencies tree with references $Artifact$ $\rightarrow$ $Node$~$Template$ and $Artifact$ $\rightarrow$ $Service$~$Template$ can be built.
\input{graphics/script_serv_tree}

\subsection{Search for Artifacts}
Since external references are stored in artifacts, we need to find all of them in order to identify the references.
The first simple solution is to analyze the structure of TOSCA application and identify all artifacts used.
But this method brings an possibility to miss some artifacts because some of them can be called from other artifacts.
This case is presented by Figure~\ref{fig:artart}.
In this example Implementation Artifact Engine calls the "Artifact 1" which calls the "Artifact 2".
The "Artifact 2" isn't called by Implementation Artifact Engine  directly and therefore will not be considered by the method described above.
The found solution is to analyze all files presented in a input CSAR and resolve external references in all of them.
We need to describe methods to identify files not described in the TOSCA topology for each supported configuration management tool.
\input{graphics/artart}

\subsection{Modules and Extensibility}
It is impossible to identify all types of external references, even when only one language and one package manager are used (an example in listing~\ref{alg:unreadable}).
\begin{Listing} 
	\caption{Unreadable bash script}
	\label{alg:unreadable}
\begin{lstlisting}
#!/bin/bash
set  line = abcdefgijklmnoprst
# The "line" contains a part of the alphabet
set  word1 = ${line:0:1}${line:14:1}${line:17:1} 
# The 1th, 15th and 18th letters of the "line" variable are stored into the "word1".
# "word1" will contain the "apt" string 
set  word2 = ${line:6:1}${line:4:1}${line:17:1}
# The 7th, 5th and 18th letters of the "line" variable are stored into the "word2".
# "word2" will contain the "get" string 
$word1-$word2 install package
# This is the "apt-get install package" command,
#		 but to determine that a good interpreter is needed.
\end{lstlisting}
\end{Listing}
Since this work is aimed at creating the easily expanded and supplemented tool, then only basic usage of package managers will be considered initially.\\
The framework should handle different languages, each of which can support various package managers.
The best solution is to develop a modular system, where modules handle different languages and package managers.
The framework will contain a  language modules and each language module will contain package managers modules.
A language module should filter files not belonging to the language and the accepted files will be transmitted to the corresponding package manager modules.
This principle can be illustrated by Figure \ref{fig:lang_pm}.\\
A package manager module resolves an external reference and transmits the package name from this reference to a package handler described in section~\ref{subs:archph}.\\
Ease of adding of new modules to the framework will prove the correctness of the architecture.\\
At the beginning the most popular combination must be developed: the $bash$ language with the $apt-get$ package manager.
This simple and powerful tool allows to install, delete or update the set of packages in one line of code.
A line-by-line parser which analyses scripts and finds the installation commands can parse such commands and will be implemented.
After the modules for this combination will be implemented and validated, new language and package manager modules can be added.
\input{graphics/languages_pm}

\subsection{Representing Downloaded Packages in a TOSCA-Topology} \label{subs:repres}
A package node denotes the defined and instantiated element of the \gls{tosca} topology, the purpose of which is to install the package.
The addition of new package nodes to the TOSCA topology can be divided into several steps.
\begin{itemize}
	\item One must add definitions for common elements like Artifact Types or Relationship Types. 
		This can be done once.
	\item The package node common definition will be represented by a Node Type. 
		It must contain the $install$ operation, which represents the capability to install the node.
		%There will be described that this node must be installed.
	\item Artifacts (the downloaded data and the installation script) will be referenced by Artifact Templates.
	\item A Node Type Implementation will combine the artifacts to implement the $install$ operation.
	\item A Node Template will instantiate the package node in the corresponding Service Templates.
		To determine the corresponding Service Template the autor will use the preprocessing described in the section~\ref{subs:analyse}.
	\item A Reference Template will provide topology information allowing the observer (a user or a runtime environment) to determine which nodes the package must be installed for.
		References will be created from the Node Template which needs the package to the Node Template of the created package nodes.
\end{itemize}
After an execution of these steps, a definition of a package node will be finished and this node can be used.

\subsection{Determining Architecture of the Final Platform} \label{finplatf}
It can be difficult to choose the architecture of the device where packages will be installed.
Unfortunately, it is impossible to analyze the structure of any CSAR and give an unambiguous answer to the question which architecture which node will be deployed on.
There are many pitfalls here.\\
A single Service Template can use several physical devices with different architectures.
Many Node Types and Node Templates instantiated on different platforms can refer to the same Implementation Artifact.
This way one simple Implementation Artifact with a bash script containing "$apt$-$get$ $install$ $python$" command can be deployed on different devices within one Service Template (for example with the arm, amd64 and i386 architectures) and will result in the loading and installation of three different packages. 
For an end user, the ability to use such a simple command is a huge advantage, but for the framework, it can greatly complicate the analysis.
The following methods of architecture selection were designed.
\begin{itemize}
	\item $Deployment$ $environment$ $analysis$\\
	The script can analyze the system where it was started (for example using the "$uname$~$-a$" command) and depending on the result, it will install the package corresponding to the system's architecture.
	\item $Unified$ $architecture$\\
	The architecture will be defined by the user for the whole CSAR.
	\item $Artifact$ $specific$ $architecture$\\
	The architecture will be defined for each artifact separately.
\end{itemize}
%\subsubsection*{Analysis of methods}
The $deployment$ $environment$ $analysis$, which at first sight seems to be the most reliable solution, brings many additional problems.
Packages for different platforms can differ not only by architecture but also by the version and the list of dependencies.
As a consequence, chaos may occur while  mirroring these different packages with different versions to the \gls{tosca} topology.
The only found robust solution is to create a set of archives for each installed package. Using this method, data for one architecture are stored into one archive.
Such archives will contain the entire dependency tree for the given package.
But this approach contradicts one of the main ideas of this work: the dependencies trees should be mapped to the topology.\\
The $artifact$ $specific$ $architecture$ method carries an additional complexity to the user of the framework.
It will make a user to analyze each artifact and decide which architecture it will be executed on. 
This can be complicated by the fact that the same artifact can be executed on different architectures.\\
The method of the $unified$ $architecture$ was chosen as the simplest and easiest to implement.
If it will be necessary, this method can easily be expanded to the $artifact$ $specific$ $architectures$ method (by removing the user input at start, and choosing an architecture for each artifact separately) or to $deployment$ $environment$ $analysis$ (by downloading packages for all available architectures and adding the architecture determining algorithm to the installation scripts).

%\subsection{Extensibility}
%The framework should handle different languages, each of them can support various package managers.
%An language module should filter files not belonging to the language, accepted files will be processed 
%This principle can be illustrated by a Figure \ref{fig:lang_pm}.
%\input{graphics/languages_pm}

\subsection{Validation}
Checking the output of the framework is an important stage in the development of the program.
It is necessary to verify both the internal correctness of the output \gls{csar} and the possibility to deploy generated package nodes.
The validity of internal dependencies can be checked by $Winery$ tool from OpenTOSCA.
This tool for creating and editing CSAR archives is also great for visualizing the results.
Checking the deployment of the generated package nodes can be done manually by entering commands which start the  artifact's execution.

\subsection{Single Node Mode}
Besides the required mode of operation, the sets of packages mode described in section~\ref{mode:setsofpkg} will be  developed to provide possibility to generate relatively small encapsulated applications.
This additional mode will be called the single node mode.
To create the sets properly, the framework must combine the information about all needed packages and then create a single TOSCA node for all of them.


\section{Architecture}\label{sec:arch}
This section will present the architecture of the framework and the detailed description of its elements.
The main elements are a \boldmath $CSAR$ $handler$, a $references$ $resolver$, $language$ $modules$, $package$ $manager$ $modules$, a $package$ $handler$, and a $topology$ $handler$. \unboldmath

\subsection{CSAR handler} \label{subs:casr_h}
The CSAR handler provides an access to a \gls{csar} and maintains its consistency. 
It describes the processes of adding the new files (to handle the metadata), \mbox{archiving/unarchiving}, and choosing the final platform architecture. \\
The input CSAR is initially archived and must be decompressed in order to handle the content first.
When all external references will be resolved, the content will be archived to an output CSAR.
A new name-value pair must be added to the metadata for each new file integrated into the CSAR during processing. 
The name represents the full path to of the file.
The value contains the type of the file. 
This type will be used by a runtime environment to chose the right behavior. %\\ %\\
As already was mentioned in section~\ref{finplatf}, an architecture of the final platform will be chosen for the entirely CSAR.
A command line interface must be provided for a user, to allow him to chose the architecture. 
The chosen architecture must be saved to the CSAR for the case of future processing by the framework to avoid the collisions between architectures of packages.

\subsection{References Resolver} \label{subs:RR}
References Resolver is the main element, whose execution is divided into three stages: $preprocessing$, $processing$, $finishing$. \\
During the $preprocessing$ stage, the CSAR will be unarchived, common files added, and internal dependencies trees generated.
Figure \ref{fig:preproc} illustrates those steps.
During the $processing$ stage, all $language$ $modules$ will be activated, the operation is described in more detail in the next section. %\\
To finish the work all results will be packed into the output CSAR during the $finishing$ stage.
\input{graphics/preprocessing}

\subsection{Language Modules} \label{subs:archlm}
Each $language$ $module$ describes a handling of one language and chooses files written in the language.
It also contains a list of supported package manager modules.
Each language module must provide the capability to generate a TOSCA node for the given package and this node must use the same language to install the package.
For example a Bash module must provide capability to define new package nodes which use bash to install the packages.
This means that a script and definitions for Artifact Templates, a Node Type, and a Node Type Implementation should be created by a language module.\\
As it is already mentioned above, during the $processing$ stage a language module analyzes all files one by one and checks their belonging to the language. 
Any files not belonging to the described language are filtered out.
The remaining files are transferred to the language module's $package$ $manager$ $modules$.
For example, a $bash$ module will pass only files with $".sh"$ extension which start with the $"\#!/bin/bash"$ line.
An $ansible$ module should have an additional functionality to unpack zip archives where ansible playbooks can be stored.
Since ansible playbooks don't contain a specific header or marker, the single sign of ansible files is the "$.yml$" extension. 
In the single node mode it will collect names of required packages from the corresponding package manager modules and create a single TOSCA node for all of them.

\subsection{Package Manager Modules} \label{subs:archpmm}
In normal mode a $package$ $managers$ $module$ finds external references, resolves them and transmits the package name to the $package$ $handler$ described in the next section.
After transmitting the names to the package handler, it must return the list of all required packages back to the language module to transfer them farther back to a language module.\\
Figure~\ref{fig:lang_ph} illustrates data flow between language modules, package manager modules and the package handler.
To resolve an external reference a package manager module will parse the given file. 
In the case of the apt-get module for bash, the module will read a file line-by-line searching for the commands starting with "apt-get install".
Such commands must be commented out and their arguments should be divided into separate package names which will be transferred to the package handler. 
\input{graphics/lang_ph}

\subsection{Package Handler} \label{subs:archph}
The $package$ $handler$ communicates with an operating system's package manager. 
It can download installation data, determine the type of dependency between packages and provide a list with dependent packages for a given package.
To download the installation data this component will use given package name and the architecture specified by the CSAR handler.
Then it transfers the package name to the $topology$ $handler$ and repeats the actions for all depended packages recursively. 
In the process it stores all names of packages from the dependency tree of original package and sends them back to the calling package manager module.
To download the data the command "apt-get download \textbf{package}" can be used. 
The architecture can be specified by a ":$architecture$" suffix, for example, a "package:arm" mean the package for the $arm$ architecture.
The list of dependencies will be obtained using the "apt-cache depends \textbf{package}" command. 
The output of such command should be parsed in order to extract names of depended packages.
Type of dependency can be achieved in the same manner.
Of course, in case of a fault during a download of a package, a user interface should be provided to find a solution.
It can be: retry the download, ignore the package, rename the package or even break the framework's execution.

\subsection{Topology Handler} \label{subs:archtop}
%This element should handle the TOSCA topology and it has two main tasks: to analyze the TOSCA topology during the preprocessing stage to create internal dependencies trees and to use those trees to create TOSCA definitions for Node Templates and Relationship Templates in the right places for the packages provided by the package handler.
This element should handle the TOSCA topology and it has two main tasks: create internal dependencies trees and generate TOSCA definitions for packages provided by the package handler.
To build the trees the analysis of the TOSCA topology will be used during the preprocessing stage.
This procedure was described in section~\ref{subs:analyse}.
The needed TOSCA definitions for new package node include Node Templates and Relationship Templates which were described in section~\ref{subs:repres}.
To create the definitions in the right places the generated internal dependencies trees will be used.
The internal dependencies trees must be updated to represent changes after addition of new Node Templates and Relationship Templates.
%$Topology$ $handler$ adds a package to the topology. 
%This includes adding new files and updating existing files. 
%Necessary steps were described in section \ref{subs:repres}.